{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e85a73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from scipy.stats import skew, kurtosis\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cd9471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Define SRM Filter Kernels ---\n",
    "# These are simplified versions of the 30+ filters found in the original SRM paper.\n",
    "# They detect residuals in different directions and orders.\n",
    "\n",
    "def get_srm_kernels():\n",
    "    kernels = []\n",
    "    \n",
    "    # 1st order: Standard differences\n",
    "    k1 = np.array([[0, 0, 0], [0, -1, 1], [0, 0, 0]], dtype=np.float32) # Horizontal\n",
    "    k2 = np.array([[0, 0, 0], [0, -1, 0], [0, 1, 0]], dtype=np.float32) # Vertical\n",
    "    \n",
    "    # 2nd order: Edge detection (Laplacian-like)\n",
    "    k3 = np.array([[0, 1, 0], [1, -4, 1], [0, 1, 0]], dtype=np.float32)\n",
    "    \n",
    "    # 3rd order: Complex residuals (approximate specific SRM types)\n",
    "    k4 = np.array([[-1, 2, -1], [2, -4, 2], [-1, 2, -1]], dtype=np.float32)\n",
    "    \n",
    "    # 5x5 High pass (captures wider dependencies)\n",
    "    k5 = np.array([[-1, 2, -2, 2, -1], \n",
    "                   [2, -6, 8, -6, 2], \n",
    "                   [-2, 8, -12, 8, -2], \n",
    "                   [2, -6, 8, -6, 2], \n",
    "                   [-1, 2, -2, 2, -1]], dtype=np.float32) / 12.0\n",
    "\n",
    "    kernels.extend([k1, k2, k3, k4, k5])\n",
    "    return kernels\n",
    "\n",
    "# --- 2. Feature Extractor ---\n",
    "\n",
    "def extract_srm_features(image_path, kernels):\n",
    "    \"\"\"\n",
    "    Reads an image, applies SRM filters, and returns statistical moments of the residuals.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read as grayscale\n",
    "        img = cv2.imread(str(image_path), cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            return None\n",
    "        \n",
    "        # Determine crop (center crop is usually best to avoid border artifacts)\n",
    "        h, w = img.shape\n",
    "        crop_size = min(512, h, w) \n",
    "        cy, cx = h // 2, w // 2\n",
    "        img_crop = img[cy - crop_size//2 : cy + crop_size//2, \n",
    "                       cx - crop_size//2 : cx + crop_size//2]\n",
    "        \n",
    "        img_float = img_crop.astype(np.float32)\n",
    "        features = []\n",
    "        \n",
    "        for k in kernels:\n",
    "            # Apply the filter\n",
    "            residual = cv2.filter2D(img_float, -1, k)\n",
    "            \n",
    "            # To handle dynamic range, we look at the statistics of the residual\n",
    "            # 1. Variance (Energy of the noise)\n",
    "            # 2. Skewness (Asymmetry of noise distribution)\n",
    "            # 3. Kurtosis (Tail heaviness - vital for detecting AI/editing)\n",
    "            \n",
    "            res_flat = residual.flatten()\n",
    "            features.append(np.var(res_flat))\n",
    "            features.append(skew(res_flat))\n",
    "            features.append(kurtosis(res_flat))\n",
    "            \n",
    "        return np.array(features)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_path}: {e}\")\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e58c115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Main Execution ---\n",
    "\n",
    "# Configuration\n",
    "IMAGE_DIR = \"/path/to/your/images\" # <--- UPDATE THIS\n",
    "ALLOWED_EXTS = {'.jpg', '.jpeg', '.png', '.tif', '.tiff', '.webp'}\n",
    "\n",
    "# Load Kernels\n",
    "kernels = get_srm_kernels()\n",
    "print(f\"Loaded {len(kernels)} SRM kernels.\")\n",
    "\n",
    "# Processing Loop\n",
    "data_features = []\n",
    "filenames = []\n",
    "\n",
    "print(\"Starting feature extraction...\")\n",
    "path_obj = Path(IMAGE_DIR)\n",
    "all_files = [p for p in path_obj.iterdir() if p.suffix.lower() in ALLOWED_EXTS]\n",
    "\n",
    "for i, img_path in enumerate(all_files):\n",
    "    if i % 10 == 0: print(f\"Processing {i}/{len(all_files)}...\")\n",
    "    \n",
    "    feats = extract_srm_features(img_path, kernels)\n",
    "    if feats is not None:\n",
    "        data_features.append(feats)\n",
    "        filenames.append(img_path.name)\n",
    "\n",
    "# Create DataFrame\n",
    "X = np.array(data_features)\n",
    "print(f\"Extraction complete. Feature matrix shape: {X.shape}\")\n",
    "\n",
    "# --- 4. Clustering & Visualization ---\n",
    "\n",
    "# A. Normalization (CRITICAL for variance/kurtosis data)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# B. Dimensionality Reduction (PCA -> t-SNE)\n",
    "# We use PCA first to suppress noise before t-SNE\n",
    "pca = PCA(n_components=min(10, X.shape[1]))\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "tsne = TSNE(n_components=2, perplexity=min(30, len(X)-1), random_state=42)\n",
    "X_embedded = tsne.fit_transform(X_pca)\n",
    "\n",
    "# C. Clustering (K-Means)\n",
    "# You might want to adjust n_clusters based on how many sources/cameras you expect\n",
    "n_clusters = 3 \n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "labels = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "# D. Plotting\n",
    "df_viz = pd.DataFrame({\n",
    "    'x': X_embedded[:, 0], \n",
    "    'y': X_embedded[:, 1], \n",
    "    'Cluster': labels, \n",
    "    'Filename': filenames\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.scatterplot(\n",
    "    data=df_viz, x='x', y='y', hue='Cluster', \n",
    "    palette='viridis', s=100, alpha=0.8, edgecolor='k'\n",
    ")\n",
    "\n",
    "plt.title('SRM Noise Analysis Clusters (t-SNE)', fontsize=16)\n",
    "plt.xlabel('Dimension 1')\n",
    "plt.ylabel('Dimension 2')\n",
    "plt.legend(title='Cluster ID', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Optional: Annotate points to spot check\n",
    "# for i in range(df_viz.shape[0]):\n",
    "#    plt.text(df_viz.x[i]+0.2, df_viz.y[i]+0.2, df_viz.Filename[i], fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clustering (3.11.14)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
